# PySpark Real Time Sceneraios

## 1.- Hot to create partitions based on year and month?
## 2.- How to handle or how to read variable/dinamic number of column of data file
## 3.- How to skip first few rows from data file
## 4.- How to handle remove duplicate records based on updated date
